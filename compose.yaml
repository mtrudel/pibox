name: docker
services:
  zigbee2mqtt:
    image: koenkk/zigbee2mqtt:latest
    restart: always
    depends_on:
      - mosquitto
    expose:
      - "8080"
    volumes:
      - zigbee2mqtt-data:/app/data
      - /run/udev:/run/udev:ro
    devices:
      - /dev/serial/by-id/usb-ITead_Sonoff_Zigbee_3.0_USB_Dongle_Plus_74c450fbdf9ced11843c7afaa7669f5d-if00-port0:/dev/ttyACM0
    environment:
      - TZ=$TIMEZONE
  homebridge:
    image: homebridge/homebridge:latest
    restart: always
    depends_on:
      - mosquitto
    networks:
      default: {}
      dockervlan:
        ipv4_address: $HOMEBRIDGE_IP_ADDRESS
    expose:
      - "8581"
    volumes:
      - homebridge-data:/homebridge
    environment:
      - TZ=$TIMEZONE
  mosquitto:
    image: eclipse-mosquitto:latest
    restart: always
    expose:
      - "1883"
    volumes:
      - mosquitto-config:/mosquitto/config
      - mosquitto-data:/mosquitto/data
      - mosquitto-log:/mosquitto/log
  hapbox:
    build: hapbox
    privileged: true
    restart: always
    networks:
      dockervlan:
        ipv4_address: $HAPBOX_IP_ADDRESS
    volumes:
      - hapbox-data:/app/_build/prod/rel/hapbox/hap_data
  zigbee2soco:
    build: https://github.com/kristianwiklund/zigbee2soco.git#main
    restart: always
    networks:
      default: {}
      dockervlan:
        ipv4_address: $ZIGBEE2SOCO_IP_ADDRESS
    environment:
      - MQTT_HOST=mosquitto
      - MQTT_PORT=1883
      - PREFIX=zigbee2mqtt
  unifi-controller:
    image: lscr.io/linuxserver/unifi-controller:latest
    restart: always
    expose:
      - "8443"
    ports:
      - "3478:3478/udp"
      - "10001:10001/udp"
      - "8080:8080"
      - "1900:1900/udp"
    volumes:
      - unifi-data:/config
    environment:
      - MEM_LIMIT=1024
  readsb:
    image: ghcr.io/sdr-enthusiasts/docker-readsb-protobuf:latest
    restart: always
    devices:
      - /dev/bus/usb:/dev/bus/usb
    environment:
      - TZ=$TIMEZONE
      - READSB_DEVICE_TYPE=rtlsdr
      - READSB_FIX=true
      - READSB_GAIN=$GAIN
      - READSB_LAT=$LAT
      - READSB_LON=$LON
      - READSB_MODEAC=true
      - READSB_RX_LOCATION_ACCURACY=2
      - READSB_STATS_RANGE=true
      - READSB_NET_ENABLE=true
      - ENABLE_PROMETHEUS=true
      - READSB_RTLSDR_PPM=$PPM
    volumes:
      - readsbpb_rrd:/run/collectd
      - readsbpb_autogain:/run/autogain
      - /proc/diskstats:/proc/diskstats:ro
    tmpfs:
      - /run/readsb:size=64M
      - /var/log:size=32M
  fr24feed:
    image: ghcr.io/sdr-enthusiasts/docker-flightradar24:latest
    restart: always
    environment:
      - BEASTHOST=readsb
      - FR24KEY=$FR24KEY
  piaware:
    image: ghcr.io/sdr-enthusiasts/docker-piaware:latest
    restart: always
    environment:
      - TZ=$TIMEZONE
      - RECEIVER_TYPE=relay
      - BEASTHOST=readsb
      - BEASTPORT=30005
      - FEEDER_ID=$PIAWARE_FEEDER_ID
    tmpfs:
      - /run:exec,size=64M
      - /var/log
  adsbexchange:
    image: ghcr.io/sdr-enthusiasts/docker-adsbexchange:latest
    restart: always
    environment:
      - BEASTHOST=readsb
      - TZ=$TIMEZONE
      - LAT=$LAT
      - LONG=$LON
      - ALT=$ALT
      - SITENAME=$ADSBEXCHANGE_SITENAME
      - UUID=$ADSBEXCHANGE_UUID
    tmpfs:
      - /run:rw,nosuid,nodev,exec,relatime,size=64M,uid=1000,gid=1000
  grafana:
    image: grafana/grafana:latest
    restart: always
    expose:
      - "3000"
    volumes:
      - grafana-data:/var/lib/grafana
    environment:
      - GF_INSTALL_PLUGINS=grafana-clock-panel,natel-discrete-panel,grafana-piechart-panel,nline-plotlyjs-panel
  prometheus:
    image: prom/prometheus:latest
    restart: always
    labels:
      docker-volume-backup.stop-during-backup: true
    expose:
      - "9090"
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.console.libraries=/etc/prometheus/console_libraries'
      - '--web.console.templates=/etc/prometheus/consoles'
      - '--storage.tsdb.retention.time=550d'
      - '--web.enable-lifecycle'
    volumes:
      - prometheus-data:/prometheus
      - ./prometheus:/etc/prometheus
  snmp:
    image: quay.io/prometheus/snmp-exporter:latest
    restart: always
    expose:
      - "9116"
  ping_exporter:
    image: czerwonk/ping_exporter:latest
    restart: always
    expose:
      - "9427"
    volumes:
      - ./ping_exporter:/config:ro
  speedtest-exporter:
    image: miguelndecarvalho/speedtest-exporter:latest
    restart: always
    expose:
      - "9798"
  hdhomerun-exporter:
    build: https://github.com/mtrudel/hdhomerun_exporter.git
    restart: always
    expose:
      - "9137"
  unpoller:
    image: golift/unifi-poller:latest
    restart: always
    expose:
      - "9130"
    environment:
      - UP_INFLUXDB_DISABLE=true
      - UP_POLLER_DEBUG=false
      - UP_UNIFI_DYNAMIC=false
      - UP_PROMETHEUS_HTTP_LISTEN=0.0.0.0:9130
      - UP_PROMETHEUS_NAMESPACE=unifipoller
      - UP_UNIFI_CONTROLLER_0_URL=$UNIFI_URI
      - UP_UNIFI_CONTROLLER_0_USER=$UNIFI_USERNAME
      - UP_UNIFI_CONTROLLER_0_PASS=$UNIFI_PASSWORD
      - UP_UNIFI_CONTROLLER_0_SAVE_ALARMS=true
      - UP_UNIFI_CONTROLLER_0_SAVE_ANOMALIES=true
      - UP_UNIFI_CONTROLLER_0_SAVE_DPI=true
      - UP_UNIFI_CONTROLLER_0_SAVE_EVENTS=true
      - UP_UNIFI_CONTROLLER_0_SAVE_IDS=true
      - UP_UNIFI_CONTROLLER_0_SAVE_SITES=true
  node_exporter:
    image: quay.io/prometheus/node-exporter:latest
    restart: always
    expose:
      - "9100"
    command:
      - '--path.rootfs=/host'
    volumes:
      - '/:/host:ro,rslave'
  ecobee_exporter:
    build: https://github.com/cfunkhouser/promobee.git
    restart: always
    expose:
      - "8080"
    volumes:
      - promobee-data:/var/run/promobee
    command:
      - '$ECOBEE_API_KEY'
  waveplus_exporter:
    build: https://github.com/mtrudel/waveplus_exporter.git#docker_support
    privileged: true
    restart: always
    network_mode: host
    environment:
      - WAVEPLUS_SERIALNUM=$WAVEPLUS_SERIALNUM
    volumes:
      - '/var/run/dbus/:/var/run/dbus/'
  mqtt_exporter:
    build: https://github.com/hikhvar/mqtt2prometheus.git
    restart: always
    expose:
      - "9641"
    volumes:
      - ./mqtt_exporter/config.yaml:/config.yaml:ro
  pidp11:
    build: pidp11
    privileged: true
    restart: always
  shellbox:
    build: shellbox
    restart: always
    hostname: shellbox
    stdin_open: true
    tty: true
    volumes:
      - shellbox-root-home:/root
  cups:
    image: chuckcharlie/cups-avahi-airprint:latest
    restart: always
    networks:
      dockervlan:
        ipv4_address: $CUPS_IP_ADDRESS
    expose:
      - "631"
    volumes:
      - cups-config:/config
      - cups-services:/services
    environment:
      - CUPSADMIN=$CUPS_USERNAME
      - CUPSPASSWORD=$CUPS_PASSWORD
  caddy:
    image: caddy:latest
    restart: always
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - caddy-data:/data
      - ./caddy/Caddyfile:/etc/caddy/Caddyfile
  tailscale:
    # A one-time setup of this container is required. Run something like:
    #
    # docker compose exec tailscale tailscale up --advertise-exit-node --advertise-routes=192.168.10.0/24
    #
    # to add this node to your tailnet. Note that you'll likely need to approve the exit node / subnet routes
    # in the tailscale admin panel
    #
    image: tailscale/tailscale:latest
    restart: always
    hostname: tailscale-docker
    cap_add:
      - NET_ADMIN
      - SYS_MODULE
    entrypoint: tailscaled
    volumes:
      - tailscale-data:/var/lib/tailscale/
    devices:
      - /dev/net/tun
  backup:
    image: offen/docker-volume-backup:latest
    restart: always
    volumes:
      - zigbee2mqtt-data:/backup/zigbee2mqtt-data:ro
      - homebridge-data:/backup/homebridge-data:ro
      - mosquitto-config:/backup/mosquitto-config:ro
      - mosquitto-data:/backup/mosquitto-data:ro
      - hapbox-data:/backup/hapbox-data:ro
      - unifi-data:/backup/unifi-data:ro
      - grafana-data:/backup/grafana-data:ro
      - prometheus-data:/backup/prometheus-data:ro
      - promobee-data:/backup/promobee-data:ro
      - shellbox-root-home:/backup/shellbox-root-home:ro
      - cups-config:/backup/cups-config:ro
      - cups-services:/backup/cups-services:ro
      - caddy-data:/backup/caddy-data:ro
      # Note that tailscale-data is purposely not backed up
      - ./archive:/archive
      - /var/run/docker.sock:/var/run/docker.sock:ro
    environment:
      - BACKUP_CRON_EXPRESSION=0 7 * * *
      - BACKUP_RETENTION_DAYS=3
      - AWS_STORAGE_CLASS=GLACIER
      - AWS_S3_BUCKET_NAME=$AWS_S3_BUCKET_NAME
      - AWS_ACCESS_KEY_ID=$AWS_ACCESS_KEY_ID
      - AWS_SECRET_ACCESS_KEY=$AWS_SECRET_ACCESS_KEY
networks:
  dockervlan:
    name: dockervlan
    external: true
volumes:
  zigbee2mqtt-data:
  homebridge-data:
  mosquitto-config:
  mosquitto-data:
  mosquitto-log:
  hapbox-data:
  readsbpb_rrd:
  readsbpb_autogain:
  unifi-data:
  grafana-data:
  prometheus-data:
  promobee-data:
  shellbox-root-home:
  cups-config:
  cups-services:
  caddy-data:
  tailscale-data:
include:
  - compose.private.yaml
